//for running the pipeline linne on cluster;
import java.nio.file.Path

val subjectPath = Val[Path]
val subjectFilename = Val[String]

val sessionID = Val[String]
val age = Val[String]
val subjectID = Val[String]
val T1para = Val[String]
val T2para = Val[String]


val threads = 8

val dataLoc = "/vol/biomedic/users/jgao/dhcp/data"

val container =
  ContainerTask(
    "biomedia/dhcp-structural-pipeline:latest",
    s"""$${subjectID} $${sessionID} $${age} -d /data/results $${T1para} $${T2para} -t $threads"""
  ) set (
    //resources += workDirectory / "matrix.py",
    hostFiles += (dataLoc, "/data"),
    (inputs, outputs) += (age, subjectID, sessionID, T1para, T2para),
    //inputs += (age, subjectID, sessionID),
    //outputs += (age, subjectID, sessionID),  // eqv to (inputs, outputs) += ()
  )
  

// extracting columns from .csv file
val s = CSVSampling("/vol/biomedic/users/jgao/dhcp/data/dataCollection.csv") set (
  columns += ("subject_ID", subjectID ),
  columns += ("session_ID", sessionID ),
  columns += ("scan_age", age),
  columns += ("T1_para", T1para),
  columns += ("T2_para", T2para),
  //columns += ("colFileName", "/path/of/the/base/dir/", f),
  // comma ',' is the default separator, but you can specify a different one using
  separator := ','
)

val env = SLURMEnvironment("jgao", "biomedia03.doc.ic.ac.uk",memory = 16 gigabytes, threads = 8)

//explo -< (container3 hook CopyFileHook(resultFile, workDirectory / "results/${subjectFilename.dropRight(4)}.csv"))

// DirectSampling works
DirectSampling (
  sampling = s,
  evaluation = container on env
)


//following line doesn't work
//(explo -< container1) -- (explo -< container2)
  
//(explo hook ToStringHook()) -- (container hook ToStringHook())
//explo hook ToStringHook()